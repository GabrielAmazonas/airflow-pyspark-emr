[AWS]
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

[S3]
CODE_BUCKET=code-bucketname
OUTPUT_BUCKET=output-bucketname
LOG_BUCKET=logs-bucketname

[SPARK]
FILE_PATH=/your/path/to/airflow-pyspark-emr/airflow_home/plugins/aws_utils/spark_jobs/etl.py

[DATALAKE]
INPUT_DATA=s3a://udacity-dend/
OUTPUT_DATA=s3a://output-bucketname/

[IAM]
ROLE_NAME=MyEmrRole